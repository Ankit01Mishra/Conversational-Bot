{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CHATBOT3",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sG7WIgg8UuKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##necessary imports :--\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import collections\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvHYyHnFfase",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()\n",
        "##Loading from data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ahllgSBfaed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.upload()\n",
        "##Loading to data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "co7zz9eYlUQ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Hyperparameters:--\n",
        "layer_size = 128\n",
        "num_layers = 2\n",
        "learning_rate = 0.001\n",
        "batch_size = 32\n",
        "epoch = 100\n",
        "max_document_length = 50\n",
        "embedding_dim = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHeLCeVtiWAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##defining some of the helper functions to create the word-embeddings\n",
        "import collections\n",
        "import re\n",
        "\n",
        "def build_dataset(words, n_words):\n",
        "  '''This function creates the required data format for passing in the RNN'''\n",
        "  \n",
        "  count = [['GO', 0], ['PAD', 1], ['EOS', 2], ['UNK', 3]]\n",
        "  count.extend(collections.Counter(words).most_common(n_words-1))\n",
        "  \n",
        "  ##initializing empty dictionary\n",
        "  dictionary = dict()\n",
        "  for word,_ in count:\n",
        "    dictionary[word] = len(dictionary)\n",
        "    \n",
        "  data = list()\n",
        "  unk_count = 0\n",
        "  for word in words:\n",
        "    index = dictionary.get(word,0)\n",
        "    if index == 0:\n",
        "      unk_count += 1\n",
        "    data.append(index)\n",
        "  count[0][1] = unk_count\n",
        "  \n",
        "  \n",
        "  reversed_dictionary = dict(zip(dictionary.values(),dictionary.keys()))\n",
        "  \n",
        "  return data,count,dictionary,reversed_dictionary\n",
        "\n",
        "\n",
        "def clean_string(string):\n",
        "  string = re.sub('[^A-Za-z0-9 ]+', '', string)\n",
        "  string = string.split(' ')\n",
        "  string = filter(None, string)\n",
        "  string = [y.strip() for y in string]\n",
        "  string = ' '.join(string)\n",
        "  return string.lower()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ea5uX1ePmQpt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Loading the dialouge data\n",
        "with open('from.txt','r') as f:\n",
        "  text_from = f.read().split('\\n')\n",
        "with open('to.txt','r') as f1:\n",
        "  text_to = f1.read().split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1xyIrdpmu5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##getting the sizes:--\n",
        "concat_from = ' '.join(text_from).split()\n",
        "size_from = len(list(set(concat_from)))\n",
        "\n",
        "concat_to = ' '.join(text_to).split()\n",
        "size_to = len(list(set(concat_to)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIltW0PEjAtz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##getting the integer representations:--\n",
        "data_from, count_from, dictionary_from, rev_dictionary_from = build_dataset(concat_from,size_from)\n",
        "data_to, count_to, dictionary_to, rev_dictionary_to = build_dataset(concat_to, size_to)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4-P24dkjoTr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GO = dictionary_from['GO']\n",
        "PAD = dictionary_from['PAD']\n",
        "EOS = dictionary_from['EOS']\n",
        "UNK = dictionary_from['UNK']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1QnPQbAVzu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##making the pipeline for the chatbot:--\n",
        "\n",
        "\n",
        "class ChatBot101(object):\n",
        "  \n",
        "  def __init__(self,layer_size,num_layers,embedding_dim,from_dict_size,to_dict_size,learning_rate,batch_size):\n",
        "    \n",
        "    def cells(reuse = False):\n",
        "      return tf.nn.rnn_cell.LSTMCell(layer_size,initializer = tf.orthogonal_initializer(),reuse = reuse)\n",
        "    self.X = tf.placeholder(tf.int32,[None,None],name = 'input')\n",
        "    self.Y = tf.placeholder(tf.int32,[None,None],name = 'output')\n",
        "    self.X_seq_len = tf.placeholder(tf.int32,[None],name = 'sequence_length_of_x')\n",
        "    self.Y_seq_len = tf.placeholder(tf.int32,[None],name = 'sequence_lenght_of_y')\n",
        "    \n",
        "    with tf.variable_scope(\"encoder_embeddings\"):\n",
        "      encoder_embeddings = tf.Variable(tf.random_uniform([from_dict_size,embedding_dim],-1,1))\n",
        "      encoder_embedded = tf.nn.embedding_lookup(encoder_embeddings,self.X)\n",
        "      after_encoder = tf.strided_slice(self.X,[0,0],[batch_size,-1],[1,1])\n",
        "      \n",
        "    with tf.variable_scope(\"decodeer_embeddings\"):\n",
        "      decoder_input = tf.concat([tf.fill([batch_size,1],GO),after_encoder],1)\n",
        "      decoder_embeddings = tf.Variable(tf.random_uniform([to_dict_size,embedding_dim],-1,1))\n",
        "      decoder_embedded = tf.nn.embedding_lookup(encoder_embeddings,decoder_input)\n",
        "      \n",
        "    with tf.variable_scope(\"encoder\"):\n",
        "      rnn_cells = tf.nn.rnn_cell.MultiRNNCell([cells() for _ in range(num_layers)])\n",
        "      _,last_state = tf.nn.dynamic_rnn(rnn_cells,encoder_embedded,dtype = tf.float32)\n",
        "      \n",
        "    with tf.variable_scope(\"decoder\"):\n",
        "      rnn_cells_dec = tf.nn.rnn_cell.MultiRNNCell([cells() for _ in range(num_layers)])\n",
        "      outputs,_ = tf.nn.dynamic_rnn(rnn_cells_dec,decoder_embedded,initial_state = last_state,dtype = tf.float32)\n",
        "\n",
        "    with tf.variable_scope(\"logits\"):\n",
        "      self.logits = tf.layers.dense(outputs,to_dict_size)\n",
        "      masks = tf.sequence_mask(self.Y_seq_len,tf.reduce_max(self.Y_seq_len),dtype = tf.float32)\n",
        "      \n",
        "    with tf.variable_scope(\"cost\"):\n",
        "      self.cost = tf.contrib.seq2seq.sequence_loss(logits = self.logits,\n",
        "                                                  targets = self.Y,\n",
        "                                                  weights = masks)\n",
        "      \n",
        "    with tf.variable_scope(\"optimizer\"):\n",
        "      opti = tf.train.AdamOptimizer(learning_rate = learning_rate)#.minimize(self.cost)\n",
        "      ##using gradient clipping\n",
        "      gradients = opti.compute_gradients(self.cost)\n",
        "      clipped_grad = [(tf.clip_by_value(grad,-1.,1.),var) for grad,var in gradients if grad is not None]\n",
        "      self.optimizer = opti.apply_gradients(clipped_grad)\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fH6p-KLoCg7q",
        "colab_type": "code",
        "outputId": "43dbc0f8-cce8-492c-e7b3-69df45647f45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "##initializatio of the model\n",
        "import os\n",
        "tf.reset_default_graph()\n",
        "sess = tf.InteractiveSession()\n",
        "\n",
        "model = ChatBot101(layer_size,num_layers,embedding_dim,size_from+4,size_to+4,learning_rate,batch_size)\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "saver = tf.train.Saver(tf.global_variables(), max_to_keep=2)\n",
        "checkpoint_dir = os.path.abspath(os.path.join('./', \"checkpoints_chatbot\"))\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"model\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bW3ji_NiFHdQ",
        "colab_type": "code",
        "outputId": "9be6f1d1-c9d3-4952-815b-f0bfa594879e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "##other helper functions:--\n",
        "\n",
        "##getting the integer representation of the words:\n",
        "def str_idx(corpus, dic):\n",
        "  X = []\n",
        "  for i in corpus:\n",
        "    ints = []\n",
        "    for k in i.split():\n",
        "      try:\n",
        "        ints.append(dic[k])\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "        ints.append(2)\n",
        "    X.append(ints)\n",
        "  return X\n",
        "\n",
        "def pad_sentence_batch(sentence_batch, pad_int):\n",
        "  padded_seqs = []\n",
        "  seq_lens = []\n",
        "  max_sentence_len = 50\n",
        "  for sentence in sentence_batch:\n",
        "    padded_seqs.append(sentence + [pad_int] * (max_sentence_len - len(sentence)))\n",
        "    seq_lens.append(50)\n",
        "  return padded_seqs, seq_lens\n",
        "\n",
        "def check_accuracy(logits, Y):\n",
        "  acc = 0\n",
        "  for i in range(logits.shape[0]):\n",
        "    internal_acc = 0\n",
        "    for k in range(len(Y[i])):\n",
        "      if Y[i][k] == logits[i][k]:\n",
        "        internal_acc += 1\n",
        "    acc += (internal_acc / len(Y[i]))\n",
        "  return acc / logits.shape[0]\n",
        "\n",
        "X = str_idx(text_from, dictionary_from)\n",
        "Y = str_idx(text_to, dictionary_to)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'lucky'\n",
            "'sad'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWLI85qkmE-T",
        "colab_type": "code",
        "outputId": "ac3e0bb8-1453-4908-cd35-ee5d05f08d1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1248
        }
      },
      "source": [
        "for i in range(epoch):\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  for k in range(0, (len(text_from) // batch_size) * batch_size, batch_size):\n",
        "    batch_x, seq_x = pad_sentence_batch(X[k: k+batch_size], PAD)\n",
        "    batch_y, seq_y = pad_sentence_batch(Y[k: k+batch_size], PAD)\n",
        "    predicted, loss, _ = sess.run([tf.argmax(model.logits,2), model.cost, model.optimizer], \n",
        "                                      feed_dict={model.X:batch_x,\n",
        "                                                model.Y:batch_y,\n",
        "                                                model.X_seq_len:seq_x,\n",
        "                                                model.Y_seq_len:seq_y})\n",
        "        \n",
        "    total_loss += loss\n",
        "    total_accuracy += check_accuracy(predicted,batch_y)\n",
        "#        print 'output:', [rev_dictionary_to[i] for i in predicted[0]]\n",
        "#        print 'input:', [rev_dictionary_to[i] for i in batch_x[0]]\n",
        "        \n",
        "  total_loss /= (len(text_from) // batch_size)\n",
        "  total_accuracy /= (len(text_from) // batch_size)\n",
        "  print('epoch: %d, avg loss: %f, avg accuracy: %f'%(i+1, total_loss, total_accuracy))\n",
        "  path = saver.save(sess, checkpoint_prefix, global_step=i+1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1, avg loss: 0.188996, avg accuracy: 0.973062\n",
            "epoch: 2, avg loss: 0.187445, avg accuracy: 0.973062\n",
            "epoch: 3, avg loss: 0.184409, avg accuracy: 0.973062\n",
            "epoch: 4, avg loss: 0.181867, avg accuracy: 0.973062\n",
            "epoch: 5, avg loss: 0.179319, avg accuracy: 0.973062\n",
            "epoch: 6, avg loss: 0.177860, avg accuracy: 0.973062\n",
            "epoch: 7, avg loss: 0.174889, avg accuracy: 0.973000\n",
            "epoch: 8, avg loss: 0.172275, avg accuracy: 0.973000\n",
            "epoch: 9, avg loss: 0.169824, avg accuracy: 0.973062\n",
            "epoch: 10, avg loss: 0.168768, avg accuracy: 0.973016\n",
            "epoch: 11, avg loss: 0.169614, avg accuracy: 0.973172\n",
            "epoch: 12, avg loss: 0.169735, avg accuracy: 0.973250\n",
            "epoch: 13, avg loss: 0.165564, avg accuracy: 0.973203\n",
            "epoch: 14, avg loss: 0.163200, avg accuracy: 0.973266\n",
            "epoch: 15, avg loss: 0.161247, avg accuracy: 0.973312\n",
            "epoch: 16, avg loss: 0.159699, avg accuracy: 0.973328\n",
            "epoch: 17, avg loss: 0.158477, avg accuracy: 0.973344\n",
            "epoch: 18, avg loss: 0.157592, avg accuracy: 0.973344\n",
            "epoch: 19, avg loss: 0.157293, avg accuracy: 0.973453\n",
            "epoch: 20, avg loss: 0.161734, avg accuracy: 0.973469\n",
            "epoch: 21, avg loss: 0.161092, avg accuracy: 0.973547\n",
            "epoch: 22, avg loss: 0.157175, avg accuracy: 0.973500\n",
            "epoch: 23, avg loss: 0.154109, avg accuracy: 0.973484\n",
            "epoch: 24, avg loss: 0.152740, avg accuracy: 0.973563\n",
            "epoch: 25, avg loss: 0.151674, avg accuracy: 0.973563\n",
            "epoch: 26, avg loss: 0.150730, avg accuracy: 0.973625\n",
            "epoch: 27, avg loss: 0.149860, avg accuracy: 0.973656\n",
            "epoch: 28, avg loss: 0.149373, avg accuracy: 0.973719\n",
            "epoch: 29, avg loss: 0.149493, avg accuracy: 0.973750\n",
            "epoch: 30, avg loss: 0.150320, avg accuracy: 0.973781\n",
            "epoch: 31, avg loss: 0.156487, avg accuracy: 0.973484\n",
            "epoch: 32, avg loss: 0.157778, avg accuracy: 0.973641\n",
            "epoch: 33, avg loss: 0.151354, avg accuracy: 0.973766\n",
            "epoch: 34, avg loss: 0.151094, avg accuracy: 0.973719\n",
            "epoch: 35, avg loss: 0.151647, avg accuracy: 0.973750\n",
            "epoch: 36, avg loss: 0.151850, avg accuracy: 0.973766\n",
            "epoch: 37, avg loss: 0.152689, avg accuracy: 0.973672\n",
            "epoch: 38, avg loss: 0.152298, avg accuracy: 0.973625\n",
            "epoch: 39, avg loss: 0.150889, avg accuracy: 0.973813\n",
            "epoch: 40, avg loss: 0.148458, avg accuracy: 0.973766\n",
            "epoch: 41, avg loss: 0.146569, avg accuracy: 0.973828\n",
            "epoch: 42, avg loss: 0.144646, avg accuracy: 0.973922\n",
            "epoch: 43, avg loss: 0.143263, avg accuracy: 0.974000\n",
            "epoch: 44, avg loss: 0.142205, avg accuracy: 0.974094\n",
            "epoch: 45, avg loss: 0.141307, avg accuracy: 0.974141\n",
            "epoch: 46, avg loss: 0.140476, avg accuracy: 0.974156\n",
            "epoch: 47, avg loss: 0.139953, avg accuracy: 0.974281\n",
            "epoch: 48, avg loss: 0.139714, avg accuracy: 0.974266\n",
            "epoch: 49, avg loss: 0.140527, avg accuracy: 0.974172\n",
            "epoch: 50, avg loss: 0.140993, avg accuracy: 0.974281\n",
            "epoch: 51, avg loss: 0.141725, avg accuracy: 0.974234\n",
            "epoch: 52, avg loss: 0.142694, avg accuracy: 0.974094\n",
            "epoch: 53, avg loss: 0.143291, avg accuracy: 0.974094\n",
            "epoch: 54, avg loss: 0.142809, avg accuracy: 0.974000\n",
            "epoch: 55, avg loss: 0.140300, avg accuracy: 0.974078\n",
            "epoch: 56, avg loss: 0.137942, avg accuracy: 0.974156\n",
            "epoch: 57, avg loss: 0.135831, avg accuracy: 0.974281\n",
            "epoch: 58, avg loss: 0.134028, avg accuracy: 0.974391\n",
            "epoch: 59, avg loss: 0.132976, avg accuracy: 0.974547\n",
            "epoch: 60, avg loss: 0.132034, avg accuracy: 0.974609\n",
            "epoch: 61, avg loss: 0.132626, avg accuracy: 0.974594\n",
            "epoch: 62, avg loss: 0.131859, avg accuracy: 0.974672\n",
            "epoch: 63, avg loss: 0.131460, avg accuracy: 0.974531\n",
            "epoch: 64, avg loss: 0.130749, avg accuracy: 0.974469\n",
            "epoch: 65, avg loss: 0.130760, avg accuracy: 0.974500\n",
            "epoch: 66, avg loss: 0.130348, avg accuracy: 0.974406\n",
            "epoch: 67, avg loss: 0.130106, avg accuracy: 0.974484\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeZyVrZ9pVt8",
        "colab_type": "code",
        "outputId": "9c14ca73-950d-48a9-f2fb-9fbe3ce7c511",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json\t     data.zip  imdb_master.csv\tsample_data\n",
            "checkpoints_chatbot  from.txt  kaggle.json\tto.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nR1-RKemX68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(sentence):\n",
        "  X_in = []\n",
        "  for word in sentence.split():\n",
        "    try:\n",
        "      X_in.append(dictionary_from[word])\n",
        "    except:\n",
        "      X_in.append(PAD)\n",
        "      pass\n",
        "        \n",
        "  test, seq_x = pad_sentence_batch([X_in], PAD)\n",
        "  input_batch = np.zeros([batch_size,seq_x[0]])\n",
        "  input_batch[0] =test[0] \n",
        "        \n",
        "  log = sess.run(tf.argmax(model.logits,2), \n",
        "                                      feed_dict={\n",
        "                                              model.X:input_batch,\n",
        "                                              model.X_seq_len:seq_x,\n",
        "                                              model.Y_seq_len:seq_x\n",
        "                                              }\n",
        "                                      )\n",
        "    \n",
        "  result=' '.join(rev_dictionary_to[i] for i in log[0])\n",
        "  return result\n",
        "    \n",
        "checkpoint_file = tf.train.latest_checkpoint(os.path.join('./', 'checkpoints_chatbot'))\n",
        "saver = tf.train.import_meta_graph(\"checkpoints_chatbot/model-1.meta\")\n",
        "saver.restore(sess, checkpoint_file)\n",
        "    \n",
        "print(predict('how are you ?') )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tj8rmiy2p3Kz",
        "colab_type": "code",
        "outputId": "01b06e9b-57fb-4b33-b5a5-b478d981d100",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls checkpoints_chatbot"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint  model-1.data-00000-of-00001  model-1.index\tmodel-1.meta\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPh5A0Fsp6N9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}